# Description

This repository contains Jupyter notebooks that explore the effects of individual decoder layers in a large language model (LLM). Through practical experiments, these notebooks analyze how the performance and output of the model change as the number of layers progresses. The goal is to understand the role of each layer in text generation and to document the effect of these layers on various metrics such as BLEU, Rouge-L, and BERTScore.
## Environment Setup

Before starting, ensure that Python 3.11 is installed. Then, install the required libraries using the following command:

```bash
pip install datasets transformers peft trl tqdm
```

## Usage

1. **Load the Model:**

   The base models are:
   - LLaMa-2 (7B) [meta-llama/Llama-2-7b-hf](https://huggingface.co/meta-llama/Llama-2-7b-hf)
   - Llama-2-fine-tuned ([Assignment 1.c fine-tuned model](https://github.com/itsrojan/llm-finetuning))
  
2. **Dataset:**

    The dataset used for evaluationg is Alpaca:

    - **Alpaca**: [tatsu-lab/alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca) 
  

3. **Run the Notebook:**
   - Open the notebook in Jupyter or another compatible environment and execute the cells sequentially.


5. **Evaluate the Model:**
   - Evaluate the output of each layer to assess the performance. Metrics used include BLEU score, ROUGE-L score, and BERTScore.

### Task 2: 
Using a consistency check between different layers of a language model can be useful for checking how factual the outputs are.

The text generated by the model changes as it goes through different layers. Early layers (like 8, 16, 24) produce varied and often unrelated sentences. By the time it reaches layer 32, the output becomes more focused and consistent, indicating that the model becomes more certain of what it's saying as it processes the information more deeply. This high confidence suggests that the final output is reliable.

Checking how consistent the outputs are across different layers could help us understand at which point the model starts producing reliable and factual text. This approach seems promising based on the high confidence and stability seen in later layers, like layer 32. This method might need more testing with different texts to see if it works well in other scenarios too.


### Task 3: 

## Average Scores

| Layer     | BLEU Score                  | ROUGE-L Score           | BERTScore             |
|-----------|-----------------------------|-------------------------|-----------------------|
| Layer 8   | 0.0                         | 0.005847953216374269    | 0.7701817949612936    |
| Layer 16  | 2.131077415413766e-09       | 0.011695906432748537    | 0.7627338667710623    |
| Layer 24  | 0.10354390070393855         | 0.2345180023228804      | 0.8339886784553527    |
| Layer 32  | 0.1729871495321498          | 0.3130216251010039      | 0.8921485543251038    |

In a language model, different layers have varying effects on how well the model's outputs match up to expected standards, measured by metrics like BLEU, ROUGE-L, and BERTScore.

1. **Layer 8:** This early layer has very low scores across all metrics. This suggests that at this stage, the model's outputs are not very similar to expected or ideal answers. It's still starting to process the input.

2. **Layer 16:** There's a slight improvement in the ROUGE-L score, but the BLEU score remains nearly zero, and BERTScore decreases a bit. This indicates some progress, but the output is still not aligning well with expected results.

3. **Layer 24:** Here, we see a noticeable jump in all scores. The BLEU score becomes significantly higher, and ROUGE-L score more than doubles compared to layer 16. BERTScore also increases, showing that the output is getting closer to what is expected.

4. **Layer 32:** This layer shows the best results. All scores are higher than in previous layers, with notable improvements in how closely the output matches the expected text. This indicates that by this final layer, the model's output is much more accurate and reliable.

As the data moves through the layers in the model, the quality of the output improves significantly. Early layers might not produce useful results, but as the information is processed through more layers, the output becomes more accurate and aligns better with what is expected. This shows the importance of allowing the model to fully process the input through all its layers for the best results.

### References
https://pytorch.org/docs/2.2/

https://huggingface.co/docs/transformers/index

